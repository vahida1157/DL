{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSVaiXjOEdSI",
        "outputId": "7b9f8fe7-b235-4964-b25b-82e79e8d6600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿\n",
            "\n",
            "*******************************************************************\n",
            "this ebook was one of project gutenberg's early files produced at a\n",
            "time when proofing methods and tools were not well developed.\n",
            "Number of unique words: 14658\n",
            "Total characters: 535814\n",
            "Total vocabulary (unique characters): 72\n",
            "['\\t', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', 'à', 'æ', '—', '‘', '’', '“', '”', '\\ufeff']\n",
            "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '#': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, '*': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '<': 29, '=': 30, '>': 31, '?': 32, '@': 33, '[': 34, ']': 35, '_': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'w': 59, 'x': 60, 'y': 61, 'z': 62, '~': 63, 'à': 64, 'æ': 65, '—': 66, '‘': 67, '’': 68, '“': 69, '”': 70, '\\ufeff': 71}\n",
            "(3348, 160, 72)\n",
            "(3348, 160, 72)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 700)         2164400   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 700)         3922800   \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 72)         50472     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,137,672\n",
            "Trainable params: 6,137,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 120/301\n",
            " 6/34 [====>.........................] - ETA: 6s - loss: 1.6260WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0968s vs `on_train_batch_end` time: 0.1359s). Check your callbacks.\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.6047\n",
            "Epoch 120: loss improved from inf to 1.60468, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_120_loss_1.6047.hdf5\n",
            "34/34 [==============================] - 16s 227ms/step - loss: 1.6047\n",
            "Epoch 121/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5870\n",
            "My Three Books Collection are:\n",
            "e the point. there is a matter shall be well.\n",
            "    i would thou weep upon the world is not the sound.\n",
            "    the world is not to more than the say so.\n",
            "    thou art not songue; be the beant me to thee.\n",
            "    the prece of mentage is not for the world.\n",
            "    the world is not to more than the san sound.\n",
            "    the fair is not to more than their lies lies,\n",
            "    the world is not to more than their dear loves,\n",
            "    the present cousin loves the world is not.\n",
            "    the efore is not the sease of my bears.\n",
            "    so shall be\n",
            "\n",
            "Epoch 121: loss improved from 1.60468 to 1.58698, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_121_loss_1.5870.hdf5\n",
            "34/34 [==============================] - 35s 1s/step - loss: 1.5870\n",
            "Epoch 122/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5861\n",
            "Epoch 122: loss improved from 1.58698 to 1.58612, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_122_loss_1.5861.hdf5\n",
            "34/34 [==============================] - 8s 234ms/step - loss: 1.5861\n",
            "Epoch 123/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5816\n",
            "Epoch 123: loss improved from 1.58612 to 1.58160, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_123_loss_1.5816.hdf5\n",
            "34/34 [==============================] - 8s 236ms/step - loss: 1.5816\n",
            "Epoch 124/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5766\n",
            "Epoch 124: loss improved from 1.58160 to 1.57658, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_124_loss_1.5766.hdf5\n",
            "34/34 [==============================] - 8s 241ms/step - loss: 1.5766\n",
            "Epoch 125/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5737\n",
            "Epoch 125: loss improved from 1.57658 to 1.57370, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_125_loss_1.5737.hdf5\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.5737\n",
            "Epoch 126/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5709\n",
            "Epoch 126: loss improved from 1.57370 to 1.57092, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_126_loss_1.5709.hdf5\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5709\n",
            "Epoch 127/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5647\n",
            "Epoch 127: loss improved from 1.57092 to 1.56471, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_127_loss_1.5647.hdf5\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5647\n",
            "Epoch 128/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5919\n",
            "Epoch 128: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 240ms/step - loss: 1.5919\n",
            "Epoch 129/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5925\n",
            "Epoch 129: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 241ms/step - loss: 1.5925\n",
            "Epoch 130/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5904\n",
            "Epoch 130: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 240ms/step - loss: 1.5904\n",
            "Epoch 131/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5894\n",
            "My Three Books Collection are:\n",
            "ur of the project gutenberg-tm conlection will\n",
            "remain freely available for cornegied this work.\n",
            "\n",
            "1.e.4. do not unlink or detach or remove the full project gutenberg-tm\n",
            "license terms from this work in any other project gutenberg-tm collection. despite these efforts, project gutenberg-tm electronic works\n",
            "\n",
            "1.a. by reading or using any part of this ebook, complying with the trademark license, iscluding paying royalties for any particular\n",
            "part ctatem with the derms of this agreement for keeping the\n",
            "pr\n",
            "\n",
            "Epoch 131: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 34s 1s/step - loss: 1.5894\n",
            "Epoch 132/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5857\n",
            "Epoch 132: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 238ms/step - loss: 1.5857\n",
            "Epoch 133/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5843\n",
            "Epoch 133: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 240ms/step - loss: 1.5843\n",
            "Epoch 134/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5769\n",
            "Epoch 134: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 240ms/step - loss: 1.5769\n",
            "Epoch 135/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5780\n",
            "Epoch 135: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 241ms/step - loss: 1.5780\n",
            "Epoch 136/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5739\n",
            "Epoch 136: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 241ms/step - loss: 1.5739\n",
            "Epoch 137/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5733\n",
            "Epoch 137: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.5733\n",
            "Epoch 138/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5678\n",
            "Epoch 138: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.5678\n",
            "Epoch 139/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5651\n",
            "Epoch 139: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5651\n",
            "Epoch 140/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5675\n",
            "Epoch 140: loss did not improve from 1.56471\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5675\n",
            "Epoch 141/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5615\n",
            "My Three Books Collection are:\n",
            "8 [_exeunt._]\n",
            "\n",
            "scene vi. another room in the castle.\n",
            "\n",
            " enter othello, iago and attendants.\n",
            "\n",
            "othello.\n",
            "i have another sorry to the castle.\n",
            "scene iii. cyprus. a room in the castle.\n",
            "\n",
            " enter othello, iago and attendants.\n",
            "\n",
            "othello.\n",
            "i have another sorry to the castle.\n",
            "scene iii. cyprus. a room in the castle.\n",
            "\n",
            " enter othello, iago and attendants.\n",
            "\n",
            "othello.\n",
            "i have another sorry to the castle.\n",
            "scene iii. cyprus. a room in the castle.\n",
            "\n",
            " enter othello, iago and attendants.\n",
            "\n",
            "othello.\n",
            "i have another sorry to t\n",
            "\n",
            "Epoch 141: loss improved from 1.56471 to 1.56147, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_141_loss_1.5615.hdf5\n",
            "34/34 [==============================] - 34s 1s/step - loss: 1.5615\n",
            "Epoch 142/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5602\n",
            "Epoch 142: loss improved from 1.56147 to 1.56023, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_142_loss_1.5602.hdf5\n",
            "34/34 [==============================] - 8s 244ms/step - loss: 1.5602\n",
            "Epoch 143/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5572\n",
            "Epoch 143: loss improved from 1.56023 to 1.55718, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_143_loss_1.5572.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.5572\n",
            "Epoch 144/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5534\n",
            "Epoch 144: loss improved from 1.55718 to 1.55341, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_144_loss_1.5534.hdf5\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.5534\n",
            "Epoch 145/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5746\n",
            "Epoch 145: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5746\n",
            "Epoch 146/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5704\n",
            "Epoch 146: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5704\n",
            "Epoch 147/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5745\n",
            "Epoch 147: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5745\n",
            "Epoch 148/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5696\n",
            "Epoch 148: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5696\n",
            "Epoch 149/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5654\n",
            "Epoch 149: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5654\n",
            "Epoch 150/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5668\n",
            "Epoch 150: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5668\n",
            "Epoch 151/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5692\n",
            "My Three Books Collection are:\n",
            "<the project gutenberg-tm concept and trademark. project gutenberg-tm electronic works\n",
            "\n",
            "1.a. by reading or using any part of this work in any other work associated with project gutenberg-tm.\n",
            "\n",
            "1.e.5. do not copy, display, perform, distribute or redistribute this\n",
            "electronic work, or any part of this electronic work, without\n",
            "prominently displaying the sentence set forth in paragraph 1.e.1 with\n",
            "active links of immediate access to the full terms of this agreement. you may obtain a refund from the\n",
            "pers\n",
            "\n",
            "Epoch 151: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 34s 1s/step - loss: 1.5692\n",
            "Epoch 152/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5640\n",
            "Epoch 152: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 242ms/step - loss: 1.5640\n",
            "Epoch 153/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5621\n",
            "Epoch 153: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.5621\n",
            "Epoch 154/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5543\n",
            "Epoch 154: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.5543\n",
            "Epoch 155/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5599\n",
            "Epoch 155: loss did not improve from 1.55341\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.5599\n",
            "Epoch 156/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5507\n",
            "Epoch 156: loss improved from 1.55341 to 1.55067, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_156_loss_1.5507.hdf5\n",
            "34/34 [==============================] - 9s 255ms/step - loss: 1.5507\n",
            "Epoch 157/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5474\n",
            "Epoch 157: loss improved from 1.55067 to 1.54744, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_157_loss_1.5474.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.5474\n",
            "Epoch 158/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5487\n",
            "Epoch 158: loss did not improve from 1.54744\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.5487\n",
            "Epoch 159/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5450\n",
            "Epoch 159: loss improved from 1.54744 to 1.54505, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_159_loss_1.5450.hdf5\n",
            "34/34 [==============================] - 9s 250ms/step - loss: 1.5450\n",
            "Epoch 160/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5432\n",
            "Epoch 160: loss improved from 1.54505 to 1.54315, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_160_loss_1.5432.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.5432\n",
            "Epoch 161/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5878\n",
            "My Three Books Collection are:\n",
            "ke the matter shall be said.\n",
            "    i would thou wilt not freat the world is found\n",
            "    and she will dark the lark of my ausend.\n",
            "    i would take thee with me to my fault is death.\n",
            "    in this the lark of late, by their dear loves\n",
            "    and she will dark the lark of my cearts\n",
            "    and she will dark the lack of my cearts\n",
            "    and where in comes the capulets of a rane.\n",
            "    and then i say to seek and fall of love.\n",
            "    and then i see the was of lanished bears\n",
            "    and then the freached of my fair love sears\n",
            " \n",
            "\n",
            "Epoch 161: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 34s 1s/step - loss: 1.5878\n",
            "Epoch 162/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5878\n",
            "Epoch 162: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.5878\n",
            "Epoch 163/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5800\n",
            "Epoch 163: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5800\n",
            "Epoch 164/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5806\n",
            "Epoch 164: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.5806\n",
            "Epoch 165/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5749\n",
            "Epoch 165: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.5749\n",
            "Epoch 166/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5737\n",
            "Epoch 166: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.5737\n",
            "Epoch 167/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5699\n",
            "Epoch 167: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.5699\n",
            "Epoch 168/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5717\n",
            "Epoch 168: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5717\n",
            "Epoch 169/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5795\n",
            "Epoch 169: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5795\n",
            "Epoch 170/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5701\n",
            "Epoch 170: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5701\n",
            "Epoch 171/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5796\n",
            "My Three Books Collection are:\n",
            "4. information about the mission of project gutenberg-tm\n",
            "\n",
            "project gutenberg-tm is synonymous with the free distribution of\n",
            "electronic works, by using or distributing this work\n",
            "(or any other work associated in any way with the phrase \"project\n",
            "gutenberg\" appears or with wonch phicha\"happhare donocr the project gutenberg-tm collection will\n",
            "remain freely available for gonerations to complying with the laws regulating\n",
            "charities and disclibuted project\n",
            "gutenberg-tm electronic works\n",
            "\n",
            "professor michael s\n",
            "\n",
            "Epoch 171: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 33s 978ms/step - loss: 1.5796\n",
            "Epoch 172/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5733\n",
            "Epoch 172: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 240ms/step - loss: 1.5733\n",
            "Epoch 173/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5726\n",
            "Epoch 173: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 244ms/step - loss: 1.5726\n",
            "Epoch 174/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5651\n",
            "Epoch 174: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.5651\n",
            "Epoch 175/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5679\n",
            "Epoch 175: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.5679\n",
            "Epoch 176/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5668\n",
            "Epoch 176: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.5668\n",
            "Epoch 177/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5667\n",
            "Epoch 177: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.5667\n",
            "Epoch 178/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5609\n",
            "Epoch 178: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.5609\n",
            "Epoch 179/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5594\n",
            "Epoch 179: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5594\n",
            "Epoch 180/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5566\n",
            "Epoch 180: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.5566\n",
            "Epoch 181/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5547\n",
            "My Three Books Collection are:\n",
            "#                                                            exeunt.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scene vi.\n",
            "capulet's orchard.\n",
            "\n",
            "enter romeo.\n",
            "\n",
            "  rom. he jests as servoce can st the capulets\n",
            "    and sear the lark of lave and lovel nate.\n",
            "    the fare of trief hours like a grave and flawer,\n",
            "    and then i see the world with the r stare the great\n",
            "    of my troush tears and treach of montague,\n",
            "    that love the wanton dall of love of light\n",
            "    that pressed herour of his dear lovers' ligs.\n",
            "    but to the lark of lave is love an\n",
            "\n",
            "Epoch 181: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 33s 985ms/step - loss: 1.5547\n",
            "Epoch 182/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5530\n",
            "Epoch 182: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 242ms/step - loss: 1.5530\n",
            "Epoch 183/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5487\n",
            "Epoch 183: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5487\n",
            "Epoch 184/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5482\n",
            "Epoch 184: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.5482\n",
            "Epoch 185/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5493\n",
            "Epoch 185: loss did not improve from 1.54315\n",
            "34/34 [==============================] - 9s 250ms/step - loss: 1.5493\n",
            "Epoch 186/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5400\n",
            "Epoch 186: loss improved from 1.54315 to 1.53998, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_186_loss_1.5400.hdf5\n",
            "34/34 [==============================] - 9s 255ms/step - loss: 1.5400\n",
            "Epoch 187/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5461\n",
            "Epoch 187: loss did not improve from 1.53998\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.5461\n",
            "Epoch 188/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5400\n",
            "Epoch 188: loss improved from 1.53998 to 1.53996, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_188_loss_1.5400.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.5400\n",
            "Epoch 189/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5407\n",
            "Epoch 189: loss did not improve from 1.53996\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5407\n",
            "Epoch 190/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5375\n",
            "Epoch 190: loss improved from 1.53996 to 1.53752, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_190_loss_1.5375.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.5375\n",
            "Epoch 191/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5368\n",
            "My Three Books Collection are:\n",
            "we have seen the match of his desperate farth,\n",
            "and the sense of the state and the some of the world and here of such a sight and craws and sease of some accidents and doth the sea-file his and so far are to the season of the seate and heaven with the soul of his desperate frame, and therefore come to this father’s death, and the sense of the seare and search of the world and here of some action to the country where you are located before\n",
            "using this ebook.\n",
            "\n",
            "title: hamlet, author: william shakespea\n",
            "\n",
            "Epoch 191: loss improved from 1.53752 to 1.53678, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_191_loss_1.5368.hdf5\n",
            "34/34 [==============================] - 33s 1s/step - loss: 1.5368\n",
            "Epoch 192/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5296\n",
            "Epoch 192: loss improved from 1.53678 to 1.52964, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_192_loss_1.5296.hdf5\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5296\n",
            "Epoch 193/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5325\n",
            "Epoch 193: loss did not improve from 1.52964\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5325\n",
            "Epoch 194/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5322\n",
            "Epoch 194: loss did not improve from 1.52964\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.5322\n",
            "Epoch 195/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5273\n",
            "Epoch 195: loss improved from 1.52964 to 1.52733, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_195_loss_1.5273.hdf5\n",
            "34/34 [==============================] - 9s 254ms/step - loss: 1.5273\n",
            "Epoch 196/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5256\n",
            "Epoch 196: loss improved from 1.52733 to 1.52562, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_196_loss_1.5256.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.5256\n",
            "Epoch 197/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5227\n",
            "Epoch 197: loss improved from 1.52562 to 1.52268, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_197_loss_1.5227.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.5227\n",
            "Epoch 198/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5256\n",
            "Epoch 198: loss did not improve from 1.52268\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.5256\n",
            "Epoch 199/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5229\n",
            "Epoch 199: loss did not improve from 1.52268\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5229\n",
            "Epoch 200/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5208\n",
            "Epoch 200: loss improved from 1.52268 to 1.52076, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_200_loss_1.5208.hdf5\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.5208\n",
            "Epoch 201/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5166\n",
            "My Three Books Collection are:\n",
            "we have sold thee so thy worl.\n",
            "    i  ill be ready bet my heart it his\n",
            "    and she will i be seen the county paris.\n",
            "    the world is not the crince. there are they better\n",
            "    that i have sean the county of a same.\n",
            "    the world is not to beer the connenue's doom\n",
            "    and she will bake thee an the world will stay\n",
            "    to seap to part of martua. these are not to stand\n",
            "    to soon to thee  thou const not speak about.\n",
            "    therefore thou cran'st  the crince of montague.\n",
            "    o courty paris, and thou shal\n",
            "\n",
            "Epoch 201: loss improved from 1.52076 to 1.51661, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_201_loss_1.5166.hdf5\n",
            "34/34 [==============================] - 33s 994ms/step - loss: 1.5166\n",
            "Epoch 202/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5181\n",
            "Epoch 202: loss did not improve from 1.51661\n",
            "34/34 [==============================] - 8s 241ms/step - loss: 1.5181\n",
            "Epoch 203/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5113\n",
            "Epoch 203: loss improved from 1.51661 to 1.51132, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_203_loss_1.5113.hdf5\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.5113\n",
            "Epoch 204/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5128\n",
            "Epoch 204: loss did not improve from 1.51132\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.5128\n",
            "Epoch 205/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5124\n",
            "Epoch 205: loss did not improve from 1.51132\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.5124\n",
            "Epoch 206/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5084\n",
            "Epoch 206: loss improved from 1.51132 to 1.50844, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_206_loss_1.5084.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.5084\n",
            "Epoch 207/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5182\n",
            "Epoch 207: loss did not improve from 1.50844\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.5182\n",
            "Epoch 208/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5043\n",
            "Epoch 208: loss improved from 1.50844 to 1.50427, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_208_loss_1.5043.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.5043\n",
            "Epoch 209/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5021\n",
            "Epoch 209: loss improved from 1.50427 to 1.50211, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_209_loss_1.5021.hdf5\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.5021\n",
            "Epoch 210/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5016\n",
            "Epoch 210: loss improved from 1.50211 to 1.50155, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_210_loss_1.5016.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.5016\n",
            "Epoch 211/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4991\n",
            "My Three Books Collection are:\n",
            "[_exeunt._]\n",
            "\n",
            "scene ii. a room in polonius’s house.\n",
            "\n",
            " enter laertes and ophelia.\n",
            "\n",
            "laertes. why have is this, my lord?\n",
            "\n",
            "hamlet. and she is well upon the platform and my lord?\n",
            "\n",
            "hamlet. i would i thank you where he comes.\n",
            "\n",
            " enter polonius.\n",
            "\n",
            "god bless you, sirt or majesty some from the cold. ay, they say, ‘i woll ask the sense of the world as not and little forth of thine own corcumstance and prink of distraction of mistress. prick’d to him, that i have found the fear of all the noble mother, and the \n",
            "\n",
            "Epoch 211: loss improved from 1.50155 to 1.49913, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_211_loss_1.4991.hdf5\n",
            "34/34 [==============================] - 33s 981ms/step - loss: 1.4991\n",
            "Epoch 212/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5025\n",
            "Epoch 212: loss did not improve from 1.49913\n",
            "34/34 [==============================] - 8s 241ms/step - loss: 1.5025\n",
            "Epoch 213/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5005\n",
            "Epoch 213: loss did not improve from 1.49913\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.5005\n",
            "Epoch 214/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4944\n",
            "Epoch 214: loss improved from 1.49913 to 1.49442, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_214_loss_1.4944.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4944\n",
            "Epoch 215/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4957\n",
            "Epoch 215: loss did not improve from 1.49442\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4957\n",
            "Epoch 216/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4908\n",
            "Epoch 216: loss improved from 1.49442 to 1.49077, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_216_loss_1.4908.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.4908\n",
            "Epoch 217/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4898\n",
            "Epoch 217: loss improved from 1.49077 to 1.48980, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_217_loss_1.4898.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4898\n",
            "Epoch 218/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4942\n",
            "Epoch 218: loss did not improve from 1.48980\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.4942\n",
            "Epoch 219/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4877\n",
            "Epoch 219: loss improved from 1.48980 to 1.48771, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_219_loss_1.4877.hdf5\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.4877\n",
            "Epoch 220/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4894\n",
            "Epoch 220: loss did not improve from 1.48771\n",
            "34/34 [==============================] - 8s 244ms/step - loss: 1.4894\n",
            "Epoch 221/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4871\n",
            "My Three Books Collection are:\n",
            "good morrow, good lieutenant, i am glad to see you well:\n",
            "\n",
            "othello.\n",
            "what dost thou say (it is my lodg again?\n",
            "i think it is no more be that i do not know.\n",
            "but if i say the place of my mestress were not the main and the moor and the moor and the country where not are located before\n",
            "using this ebook.\n",
            "\n",
            "title: hamlet\n",
            "\n",
            "author: william shakespeare\n",
            "\n",
            "release date: november 1998 [ebook #1524]\n",
            "[most recently updated: november 11, 2021]\n",
            "\n",
            "language: english\n",
            "\n",
            "\n",
            "produced by: the pg ghakespeare teame trane team, te\n",
            "\n",
            "Epoch 221: loss improved from 1.48771 to 1.48712, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_221_loss_1.4871.hdf5\n",
            "34/34 [==============================] - 33s 986ms/step - loss: 1.4871\n",
            "Epoch 222/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4863\n",
            "Epoch 222: loss improved from 1.48712 to 1.48627, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_222_loss_1.4863.hdf5\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.4863\n",
            "Epoch 223/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4842\n",
            "Epoch 223: loss improved from 1.48627 to 1.48421, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_223_loss_1.4842.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.4842\n",
            "Epoch 224/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4809\n",
            "Epoch 224: loss improved from 1.48421 to 1.48090, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_224_loss_1.4809.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4809\n",
            "Epoch 225/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4773\n",
            "Epoch 225: loss improved from 1.48090 to 1.47735, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_225_loss_1.4773.hdf5\n",
            "34/34 [==============================] - 9s 255ms/step - loss: 1.4773\n",
            "Epoch 226/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4753\n",
            "Epoch 226: loss improved from 1.47735 to 1.47535, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_226_loss_1.4753.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.4753\n",
            "Epoch 227/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4775\n",
            "Epoch 227: loss did not improve from 1.47535\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.4775\n",
            "Epoch 228/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4750\n",
            "Epoch 228: loss improved from 1.47535 to 1.47498, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_228_loss_1.4750.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4750\n",
            "Epoch 229/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4769\n",
            "Epoch 229: loss did not improve from 1.47498\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.4769\n",
            "Epoch 230/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4678\n",
            "Epoch 230: loss improved from 1.47498 to 1.46781, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_230_loss_1.4678.hdf5\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.4678\n",
            "Epoch 231/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4682\n",
            "My Three Books Collection are:\n",
            "% of the project gutenberg-tm trademark, but he has\n",
            "  agreed to donate royalties under this agreement when you hove ab\n",
            "thin so than allow and the foundation s website\n",
            "and official provedt gotenberg-tm electronic works. see paragraph 1.e below.\n",
            "\n",
            "1.c. the project gutenberg literary archive foundation is a non-profit\n",
            "501(c)(3) educational corporation organized under the laws of the state of mississippi and granted tax exempt status by the internal\n",
            "revenue service. the foundation's ein or federal tax\n",
            "\n",
            "Epoch 231: loss did not improve from 1.46781\n",
            "34/34 [==============================] - 33s 1s/step - loss: 1.4682\n",
            "Epoch 232/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4790\n",
            "Epoch 232: loss did not improve from 1.46781\n",
            "34/34 [==============================] - 8s 240ms/step - loss: 1.4790\n",
            "Epoch 233/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4694\n",
            "Epoch 233: loss did not improve from 1.46781\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.4694\n",
            "Epoch 234/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4662\n",
            "Epoch 234: loss improved from 1.46781 to 1.46617, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_234_loss_1.4662.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4662\n",
            "Epoch 235/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4617\n",
            "Epoch 235: loss improved from 1.46617 to 1.46171, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_235_loss_1.4617.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.4617\n",
            "Epoch 236/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4652\n",
            "Epoch 236: loss did not improve from 1.46171\n",
            "34/34 [==============================] - 9s 250ms/step - loss: 1.4652\n",
            "Epoch 237/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4608\n",
            "Epoch 237: loss improved from 1.46171 to 1.46077, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_237_loss_1.4608.hdf5\n",
            "34/34 [==============================] - 9s 254ms/step - loss: 1.4608\n",
            "Epoch 238/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4603\n",
            "Epoch 238: loss improved from 1.46077 to 1.46027, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_238_loss_1.4603.hdf5\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.4603\n",
            "Epoch 239/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4577\n",
            "Epoch 239: loss improved from 1.46027 to 1.45772, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_239_loss_1.4577.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4577\n",
            "Epoch 240/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4591\n",
            "Epoch 240: loss did not improve from 1.45772\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4591\n",
            "Epoch 241/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4578\n",
            "My Three Books Collection are:\n",
            "‘believed in this arminent could not love to see them to the moor.\n",
            "\n",
            "othello.\n",
            "what is the matter? think you?\n",
            "\n",
            "cassio.\n",
            "i more not now, but i am sore to the world.\n",
            "\n",
            "emilia.\n",
            "ay, my lord.\n",
            "\n",
            "othello.\n",
            "what is the matter? how now, good my lord?\n",
            "\n",
            "othello.\n",
            "why of thy sons?\n",
            "\n",
            "desdemona.\n",
            "i dannot sean that, but i will watch the lord\n",
            "if you did not this bely well in honest\n",
            "fand that i would do much a prove and feast\n",
            "to what i shall the world to seck the world,\n",
            "the woid the world were nothing to the soul,\n",
            "that s\n",
            "\n",
            "Epoch 241: loss did not improve from 1.45772\n",
            "34/34 [==============================] - 33s 983ms/step - loss: 1.4578\n",
            "Epoch 242/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4553\n",
            "Epoch 242: loss improved from 1.45772 to 1.45528, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_242_loss_1.4553.hdf5\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4553\n",
            "Epoch 243/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4562\n",
            "Epoch 243: loss did not improve from 1.45528\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4562\n",
            "Epoch 244/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4461\n",
            "Epoch 244: loss improved from 1.45528 to 1.44612, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_244_loss_1.4461.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4461\n",
            "Epoch 245/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4519\n",
            "Epoch 245: loss did not improve from 1.44612\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4519\n",
            "Epoch 246/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4460\n",
            "Epoch 246: loss improved from 1.44612 to 1.44599, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_246_loss_1.4460.hdf5\n",
            "34/34 [==============================] - 9s 258ms/step - loss: 1.4460\n",
            "Epoch 247/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4455\n",
            "Epoch 247: loss improved from 1.44599 to 1.44550, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_247_loss_1.4455.hdf5\n",
            "34/34 [==============================] - 9s 255ms/step - loss: 1.4455\n",
            "Epoch 248/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4441\n",
            "Epoch 248: loss improved from 1.44550 to 1.44406, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_248_loss_1.4441.hdf5\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.4441\n",
            "Epoch 249/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4445\n",
            "Epoch 249: loss did not improve from 1.44406\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.4445\n",
            "Epoch 250/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4396\n",
            "Epoch 250: loss improved from 1.44406 to 1.43957, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_250_loss_1.4396.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.4396\n",
            "Epoch 251/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4437\n",
            "My Three Books Collection are:\n",
            "; the best sirt in the chart and theep of his sich and the moor hamlet ship. which i have lost the players to the soul, they say ‘e of the mand of his since and his will is not the soul to hamlet’s bitter.\n",
            "\n",
            "queen. o heaven, i lat the door. but where is nothing but the sceep of him and his madness kill hamlet this bad begins the sears and cruft of this with honesty and when they say, the prince of the\n",
            "portision of the trade and sight of country, and in this thing it would provake his father’s deat\n",
            "\n",
            "Epoch 251: loss did not improve from 1.43957\n",
            "34/34 [==============================] - 32s 975ms/step - loss: 1.4437\n",
            "Epoch 252/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4390\n",
            "Epoch 252: loss improved from 1.43957 to 1.43905, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_252_loss_1.4390.hdf5\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4390\n",
            "Epoch 253/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4457\n",
            "Epoch 253: loss did not improve from 1.43905\n",
            "34/34 [==============================] - 8s 244ms/step - loss: 1.4457\n",
            "Epoch 254/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4318\n",
            "Epoch 254: loss improved from 1.43905 to 1.43183, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_254_loss_1.4318.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4318\n",
            "Epoch 255/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4403\n",
            "Epoch 255: loss did not improve from 1.43183\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.4403\n",
            "Epoch 256/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4361\n",
            "Epoch 256: loss did not improve from 1.43183\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.4361\n",
            "Epoch 257/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4309\n",
            "Epoch 257: loss improved from 1.43183 to 1.43089, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_257_loss_1.4309.hdf5\n",
            "34/34 [==============================] - 9s 254ms/step - loss: 1.4309\n",
            "Epoch 258/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4289\n",
            "Epoch 258: loss improved from 1.43089 to 1.42887, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_258_loss_1.4289.hdf5\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.4289\n",
            "Epoch 259/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4271\n",
            "Epoch 259: loss improved from 1.42887 to 1.42708, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_259_loss_1.4271.hdf5\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.4271\n",
            "Epoch 260/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4275\n",
            "Epoch 260: loss did not improve from 1.42708\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4275\n",
            "Epoch 261/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4281\n",
            "My Three Books Collection are:\n",
            "contribution. in this ebook of volint at\n",
            "www.gutenberg.org/license.\n",
            "\n",
            "section 1. general terms of use and redistributing project\n",
            "gutenberg-tm electronic works\n",
            "\n",
            "1.a. by reading or using any part of this work is any\n",
            "other work associated with project gutenberg-tm.\n",
            "\n",
            "1.e.5. do not copy, display, perform, distribute or redistribute this\n",
            "electronic work, or any part of this electronic work, without\n",
            "prominently displaying the sentence set forth in paragraph 1.e.1 with\n",
            "active links or immediate access to \n",
            "\n",
            "Epoch 261: loss did not improve from 1.42708\n",
            "34/34 [==============================] - 33s 1s/step - loss: 1.4281\n",
            "Epoch 262/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4271\n",
            "Epoch 262: loss did not improve from 1.42708\n",
            "34/34 [==============================] - 8s 242ms/step - loss: 1.4271\n",
            "Epoch 263/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4286\n",
            "Epoch 263: loss did not improve from 1.42708\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4286\n",
            "Epoch 264/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4240\n",
            "Epoch 264: loss improved from 1.42708 to 1.42397, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_264_loss_1.4240.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4240\n",
            "Epoch 265/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4255\n",
            "Epoch 265: loss did not improve from 1.42397\n",
            "34/34 [==============================] - 9s 250ms/step - loss: 1.4255\n",
            "Epoch 266/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4228\n",
            "Epoch 266: loss improved from 1.42397 to 1.42278, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_266_loss_1.4228.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.4228\n",
            "Epoch 267/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4171\n",
            "Epoch 267: loss improved from 1.42278 to 1.41715, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_267_loss_1.4171.hdf5\n",
            "34/34 [==============================] - 9s 254ms/step - loss: 1.4171\n",
            "Epoch 268/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4195\n",
            "Epoch 268: loss did not improve from 1.41715\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.4195\n",
            "Epoch 269/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4155\n",
            "Epoch 269: loss improved from 1.41715 to 1.41551, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_269_loss_1.4155.hdf5\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.4155\n",
            "Epoch 270/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4167\n",
            "Epoch 270: loss did not improve from 1.41551\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.4167\n",
            "Epoch 271/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4089\n",
            "My Three Books Collection are:\n",
            "2. indemnity - you agree to indemnify and hold the foundation, the\n",
            "trademark owner, any agent or employee of the foundation, anyone\n",
            "providing copies of project gutenberg-tm\n",
            "electronic works, see paragraph 1.e below.\n",
            "\n",
            "1.c. the project gutenberg literary archive foundation, the owner of the project\n",
            "gutenberg-tm trademark, and any other party distributing a project\n",
            "gutenberg-tm electronic works. see paragraph 1.e below.\n",
            "\n",
            "1.c. the project gutenberg literary archive foundation, the owner of the projec\n",
            "\n",
            "Epoch 271: loss improved from 1.41551 to 1.40890, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_271_loss_1.4089.hdf5\n",
            "34/34 [==============================] - 32s 971ms/step - loss: 1.4089\n",
            "Epoch 272/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4178\n",
            "Epoch 272: loss did not improve from 1.40890\n",
            "34/34 [==============================] - 8s 242ms/step - loss: 1.4178\n",
            "Epoch 273/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4107\n",
            "Epoch 273: loss did not improve from 1.40890\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.4107\n",
            "Epoch 274/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4039\n",
            "Epoch 274: loss improved from 1.40890 to 1.40388, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_274_loss_1.4039.hdf5\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4039\n",
            "Epoch 275/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4084\n",
            "Epoch 275: loss did not improve from 1.40388\n",
            "34/34 [==============================] - 9s 253ms/step - loss: 1.4084\n",
            "Epoch 276/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4071\n",
            "Epoch 276: loss did not improve from 1.40388\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4071\n",
            "Epoch 277/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4104\n",
            "Epoch 277: loss did not improve from 1.40388\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.4104\n",
            "Epoch 278/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4026\n",
            "Epoch 278: loss improved from 1.40388 to 1.40261, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_278_loss_1.4026.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.4026\n",
            "Epoch 279/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4081\n",
            "Epoch 279: loss did not improve from 1.40261\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.4081\n",
            "Epoch 280/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4002\n",
            "Epoch 280: loss improved from 1.40261 to 1.40025, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_280_loss_1.4002.hdf5\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.4002\n",
            "Epoch 281/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4003\n",
            "My Three Books Collection are:\n",
            "me to the project\n",
            "gutenberg-tm trademark, and any other party distributing a project\n",
            "gutenberg-tm electronic works. see paragraph 1.e below.\n",
            "\n",
            "1.c. the project gutenberg literary archive foundation (\"the\n",
            "foundation\" or pglaf), owns a compilation copyright in the collection\n",
            "of project gutenberg-tm electronic works. see paragraph 1.e below.\n",
            "\n",
            "1.c. the project gutenberg literary archive foundation (\"the\n",
            "foundation\" or pglaf), owns a compilation copyright in the collection\n",
            "of project gutenberg-tm elect\n",
            "\n",
            "Epoch 281: loss did not improve from 1.40025\n",
            "34/34 [==============================] - 33s 988ms/step - loss: 1.4003\n",
            "Epoch 282/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3993\n",
            "Epoch 282: loss improved from 1.40025 to 1.39929, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_282_loss_1.3993.hdf5\n",
            "34/34 [==============================] - 8s 245ms/step - loss: 1.3993\n",
            "Epoch 283/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3976\n",
            "Epoch 283: loss improved from 1.39929 to 1.39764, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_283_loss_1.3976.hdf5\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.3976\n",
            "Epoch 284/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3986\n",
            "Epoch 284: loss did not improve from 1.39764\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.3986\n",
            "Epoch 285/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3957\n",
            "Epoch 285: loss improved from 1.39764 to 1.39568, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_285_loss_1.3957.hdf5\n",
            "34/34 [==============================] - 9s 255ms/step - loss: 1.3957\n",
            "Epoch 286/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3953\n",
            "Epoch 286: loss improved from 1.39568 to 1.39534, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_286_loss_1.3953.hdf5\n",
            "34/34 [==============================] - 9s 255ms/step - loss: 1.3953\n",
            "Epoch 287/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3971\n",
            "Epoch 287: loss did not improve from 1.39534\n",
            "34/34 [==============================] - 8s 249ms/step - loss: 1.3971\n",
            "Epoch 288/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3890\n",
            "Epoch 288: loss improved from 1.39534 to 1.38895, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_288_loss_1.3890.hdf5\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.3890\n",
            "Epoch 289/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3897\n",
            "Epoch 289: loss did not improve from 1.38895\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.3897\n",
            "Epoch 290/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3902\n",
            "Epoch 290: loss did not improve from 1.38895\n",
            "34/34 [==============================] - 8s 244ms/step - loss: 1.3902\n",
            "Epoch 291/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3889\n",
            "My Three Books Collection are:\n",
            "5.\n",
            "\n",
            "codtait.\n",
            "if the poison fore and dire be broef,\n",
            "that deeds may chonge to shake and give the state\n",
            "that the r discourse of momenass and dead,\n",
            "they she may call it suit. but sent the seake\n",
            "that my distimes him for my partical soul,\n",
            "that the main corse of his displeasure surd,\n",
            "and she did still in such a sight of lafe,\n",
            "but i will watch him to his grave and fatch,\n",
            "when i have seen the day that i have seen.\n",
            "when me shall seek a bood and take of him.\n",
            "\n",
            " esdemona.\n",
            "he speaks will \n",
            "\n",
            "othello.\n",
            "i have a pa\n",
            "\n",
            "Epoch 291: loss improved from 1.38895 to 1.38887, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_291_loss_1.3889.hdf5\n",
            "34/34 [==============================] - 32s 973ms/step - loss: 1.3889\n",
            "Epoch 292/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3834\n",
            "Epoch 292: loss improved from 1.38887 to 1.38338, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_292_loss_1.3834.hdf5\n",
            "34/34 [==============================] - 8s 246ms/step - loss: 1.3834\n",
            "Epoch 293/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3831\n",
            "Epoch 293: loss improved from 1.38338 to 1.38315, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_293_loss_1.3831.hdf5\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.3831\n",
            "Epoch 294/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3844\n",
            "Epoch 294: loss did not improve from 1.38315\n",
            "34/34 [==============================] - 8s 248ms/step - loss: 1.3844\n",
            "Epoch 295/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3835\n",
            "Epoch 295: loss did not improve from 1.38315\n",
            "34/34 [==============================] - 9s 251ms/step - loss: 1.3835\n",
            "Epoch 296/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3813\n",
            "Epoch 296: loss improved from 1.38315 to 1.38126, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_296_loss_1.3813.hdf5\n",
            "34/34 [==============================] - 9s 256ms/step - loss: 1.3813\n",
            "Epoch 297/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3801\n",
            "Epoch 297: loss improved from 1.38126 to 1.38008, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_297_loss_1.3801.hdf5\n",
            "34/34 [==============================] - 9s 252ms/step - loss: 1.3801\n",
            "Epoch 298/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3816\n",
            "Epoch 298: loss did not improve from 1.38008\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.3816\n",
            "Epoch 299/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3738\n",
            "Epoch 299: loss improved from 1.38008 to 1.37383, saving model to /content/drive/MyDrive/ML/weights/weights_epoch_299_loss_1.3738.hdf5\n",
            "34/34 [==============================] - 8s 250ms/step - loss: 1.3738\n",
            "Epoch 300/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3782\n",
            "Epoch 300: loss did not improve from 1.37383\n",
            "34/34 [==============================] - 8s 247ms/step - loss: 1.3782\n",
            "Epoch 301/301\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3764\n",
            "My Three Books Collection are:\n",
            "good morrow, good lieutenant; i am sorry to your father.\n",
            "\n",
            "othello.\n",
            "what is the matter, lieutenant?\n",
            "\n",
            "cassio.\n",
            "ay, but all the grest culle to the citadel,\n",
            "and he shall keep her and his loveling drom\n",
            "\n",
            "he shall incompossed me to such a sight,\n",
            "that she should muke a little with my lord,\n",
            "nor she will see the watch of my merrow\n",
            "and the mort in it. if the belach of my cousen\n",
            "\n",
            "o have it see to ford of heaven, the general gards of dire, and they she loves\n",
            "the moor against the world, there bre their besiess,\n",
            "\n",
            "Epoch 301: loss did not improve from 1.37383\n",
            "34/34 [==============================] - 34s 1s/step - loss: 1.3764\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb38c155e90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from string import punctuation\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Romeo and Juliet by William Shakespeare\n",
        "content1 = requests.get(\"https://www.gutenberg.org/cache/epub/1777/pg1777.txt\").text\n",
        "# Hamlet, Prince of Denmark by William Shakespeare\n",
        "content2 = requests.get(\"https://www.gutenberg.org/cache/epub/1524/pg1524.txt\").text\n",
        "# Othello, the Moor of Venice by William Shakespeare\n",
        "content3 = requests.get(\"https://www.gutenberg.org/cache/epub/1531/pg1531.txt\").text\n",
        "open(\"3Books.txt\", \"w\", encoding=\"utf-8\").write(content1 + content2 + content3)\n",
        "\n",
        "#training_file = 'warpeace.txt'\n",
        "training_file = '3Books.txt'\n",
        "\n",
        "raw_text = open(training_file, 'r').read()\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "print(raw_text[:200])\n",
        "\n",
        "all_words = raw_text.split()\n",
        "unique_words = list(set(all_words))\n",
        "print(f'Number of unique words: {len(unique_words)}')\n",
        "n_chars = len(raw_text)\n",
        "print(f'Total characters: {n_chars}')\n",
        "\n",
        "chars = sorted(list(set(raw_text)))\n",
        "n_vocab = len(chars)\n",
        "print(f'Total vocabulary (unique characters): {n_vocab}')\n",
        "print(chars)\n",
        "\n",
        "index_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
        "print(char_to_index)\n",
        "\n",
        "seq_length = 160\n",
        "n_seq = int(n_chars / seq_length)\n",
        "\n",
        "X = np.zeros((n_seq, seq_length, n_vocab))\n",
        "Y = np.zeros((n_seq, seq_length, n_vocab))\n",
        "\n",
        "for i in range(n_seq):\n",
        "\tx_sequence = raw_text[i * seq_length : (i + 1) * seq_length]\n",
        "\tx_sequence_ohe = np.zeros((seq_length, n_vocab))\n",
        "\tfor j in range(seq_length):\n",
        "\t\tchar = x_sequence[j]\n",
        "\t\tindex = char_to_index[char]\n",
        "\t\tx_sequence_ohe[j][index] = 1.\n",
        "\tX[i] = x_sequence_ohe\n",
        "\ty_sequence = raw_text[i * seq_length + 1 : (i + 1) * seq_length + 1]\n",
        "\ty_sequence_ohe = np.zeros((seq_length, n_vocab))\n",
        "\tfor j in range(seq_length):\n",
        "\t\tchar = y_sequence[j]\n",
        "\t\tindex = char_to_index[char]\n",
        "\t\ty_sequence_ohe[j][index] = 1.\n",
        "\tY[i] = y_sequence_ohe\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "batch_size = 100\n",
        "hidden_units = 700\n",
        "n_epoch= 301\n",
        "dropout = 0.4\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.LSTM(hidden_units, input_shape=(None, n_vocab), return_sequences=True, dropout=dropout))\n",
        "model.add(layers.LSTM(hidden_units, return_sequences=True, dropout=dropout))\n",
        "model.add(layers.TimeDistributed(layers.Dense(n_vocab, activation='softmax')))\n",
        "\n",
        "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "filepath=\"/content/drive/MyDrive/ML/weights/weights_epoch_{epoch:03d}_loss_{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=50, verbose=1, mode='min')\n",
        "\n",
        "def generate_text(model, gen_length, n_vocab, index_to_char):\n",
        "    \"\"\"\n",
        "    Generating text using the RNN model\n",
        "    @param model: current RNN model\n",
        "    @param gen_length: number of characters we want to generate\n",
        "    @param n_vocab: number of unique characters\n",
        "    @param index_to_char: index to character mapping\n",
        "    @return:\n",
        "    \"\"\"\n",
        "    # Start with a randomly picked character\n",
        "    index = np.random.randint(n_vocab)\n",
        "    y_char = [index_to_char[index]]\n",
        "    X = np.zeros((1, gen_length, n_vocab))\n",
        "    for i in range(gen_length):\n",
        "        X[0, i, index] = 1.\n",
        "        indices = np.argmax(model.predict(X[:, max(0, i - 99):i + 1, :])[0], 1)\n",
        "        index = indices[-1]\n",
        "        y_char.append(index_to_char[index])\n",
        "    return ''.join(y_char)\n",
        "\n",
        "class ResultChecker(Callback):\n",
        "    def __init__(self, model, N, gen_length):\n",
        "        self.model = model\n",
        "        self.N = N\n",
        "        self.gen_length = gen_length\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.N == 0:\n",
        "            result = generate_text(self.model, self.gen_length, n_vocab, index_to_char)\n",
        "            print('\\nMy Three Books Collection are:\\n' + result)\n",
        "\n",
        "result_checker = ResultChecker(model, 10, 500)\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/ML/weights/weights_epoch_120_loss_1.6613.hdf5\")\n",
        "model.fit(X, Y, batch_size=batch_size, verbose=1, epochs=n_epoch,initial_epoch=119,\n",
        "                 callbacks=[result_checker, checkpoint, early_stop])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}